## 1 - 计算机系统漫游

---

### 1. 信息就是位＋上下文

```C
#include <stdio.h>

int main()
{
	printf("hello, world\n");
	return 0;
}
```

hello 程序的生命周期是从一个源程序（或者说源文件）开始，实际上就是一个由值 0 和
1 组成的位（又称为bit）序列，8 个位被组织成一组称为字节。大部分的现代计算机系统都使用 ASCII 标准来表示文本字符，如下图所示的 hello.c 程序的 ASCII 码：

![](/images/CSAPP/Pasted%20image%2020250110220436.png)

hello.c 的表示方法说明了一个**基本思想**：系统中所有的信息——包括磁盘文件、内存中的程序、内存中存放的用户数据以及网络上传送的数据，**都是由一串比特表示的**。区分不同数据对象的唯 一 方法是我们读到这些数据对象时的上下文 。比如，在不同的上下文中，一个同样的字节序列可能表示一个整数 、 浮点数、字符串或者机器指令。

### 2. 程序被其他程序翻译成不同的格式

为了在系统上运行 hello.c 程序，每条 C 语句都必须被其他程序转化为一系列的低级机器语言指令，然后这些指令按照一种称为可执行目标程序的格式打好包，并以二进制磁盘文件的形式存放起来。这个翻译过程可分为四个阶段完成（预处理器、编译器、汇编器和链接器）。下图是编译系统对程序的编译过程：

![](/images/CSAPP/Pasted%20image%2020250110220847.png)

- **预处理阶段**：预处理器 (cpp) 根据以字符＃开头的命令，修改原始的 C 程序。比如 hello.c 中第 1 行的 `#include <stdio. h>` 命令告诉预处理器读取系统头文件 stdio.h 的内容，并把它直接插入程序文本中，通常是以 .i 作为文件扩展名；
- **编译阶段**：编译器 (eel) 将文本文件 hello.i 翻译成文本文件 hello.s，即**汇编代码**；
- **汇编阶段**：汇编器 (as) 将 hello.s 翻译成**机器语言指令**，把这些指令打包成一种叫做可重定位目标程序 (*relocatable object program*) 的格式，并将结果保存在二进制目标文件 hello.o 中。
- **链接阶段**：链接标准 C 库中预编译好的 printf 函数，链接器 (Id) 将 printf.o 与 hello.o 合并得到**可执行文件**

### 3. 了解编译系统如何工作是大有益处的

- **优化程序性能**：比如，一个 switch 语句是否总是比一系列的  if-else 语句高效得多？一个函数调用的开销有多大?while 循环比 for 循环更有效吗？指针引用比数组索引更有效吗？为什么将循环求和的结果放到一个本地变量中，会比将其放到 个通过引用传递过来的参数中，运行起来快很多呢？为什么只是简单地重新排列一下算术表达式中的括号就能让函数运行得更快？
- **理解链接时出现的错误**：比如，链接器报告说它无法解析一个引用，这是什么意思？静态变量和全局变量的区别是什么？如果在不同的 C 文件中定义了名字相同的两个全局变量会发生什么？静态库和动态库的区别是什么？在命令行上排列库的顺序有什么影响？最严重的是，为什么有些链接错误直到运行时才会出现？
- **避免安全漏洞**：缓冲区溢出错误是造成大多数网络和服务器上安全漏洞的主要原因。存在这些错误是因为很少有程序员能够理解需要限制从不受信任的源接收数据的数量和格式。学习安全编程的第一步就是**理解数据和控制信息存储在程序栈上的方式会引起的后果**。

### 4. 处理器读并解释储存在内存中的指令

#### 4.1. 系统的硬件组成

![](/images/CSAPP/Pasted%20image%2020250110221846.png)

1. **总线**：贯穿整个系统的一组电子管道，它**携带信息字节并负责在各个部件间传递**。通常总线被设计成传送定长的字节块，也就是字 (word) 。现在的大多数机器字长要么是 4 个字节 (32位），要么是 8 个字节 (64 位）
2. **I/O 设备**：**系统与外部世界的联系通道**。图中的I/O 设备有键盘、鼠标、显示器和磁盘。每个 I/O 设备都通过一个控制器或适配器与 I/O 总线相连。控制器是  I/O 设备本身或者系统的主印制电路板（通常称作 主板）上的芯片组。而适配器则是一块插在主板插槽上的卡 
3. **主存**：临时存储设备，在处理器执行程序时，用来存**放程序和程序处理的数据**。从**物理上**来说，主存是由一组动态随机存取存储器 (DRAM) 芯片组成的。从**逻辑上**来说，存储器是一个线性的字节数组，每个字节都有其唯一的地址（数组索引），这些地址是从零开始的。 
4. **处理器**：**解释（或执行）存储在主存中指令的引擎**。处理器的核心是一个大小为一个字的存储设备（或寄存器），称为程序计数器 (PC) 。在任何时刻，PC 都指向主存中的某条机器语言指令（即含有该条指令的地址）。从系统通电开始，直到系统断电，处理器一直在不断地执行程序计数器指向的指令，再更新程序计数器，使其指向下一条指令。CPU 在指令的要求下可能会执行这些操作。
   - **加载**：从主存复制一个字节或者一个字到寄存器，以覆盖寄存器原来的内容；
   - **存储**：从寄存器复制一个字节或者一个字到主存的某个位置，以覆盖这个位置上原来的内容；
   - **操作**：把两个寄存器的内容复制到算术／逻辑单元 (ALU)，ALU 对这两个字做算术运算，并将结果存放到一个寄存器中，以覆盖该寄存器中原来的内容；
   - **跳转**：从指令本身中抽取一个字，并将这个字复制到程序计数器 (PC) 中，以覆盖 PC 中原来的值

#### 4.2. 运行 hello 程序

- shell 程序执行它的指令，等待输入一个命令 。 在键盘上输入字符串 `"./hello"` 后，shell 程序将字符逐一读入寄存器，再把它存放到内存中；
  ![](/images/CSAPP/Pasted%20image%2020250110223049.png)
- 当在键盘上敲回车键时，shell 执行一系列指令来加载可执行的 hello 文件，这些指令将 hello 目标文件中的代码和数据从磁盘复制到主存。数据包括最终会被输出的字符串 `"hello, world\n"`。利用直接存储器存取（DMA）技术，数据可以不通过处理器而直接从磁盘到达主存；
  ![](/images/CSAPP/Pasted%20image%2020250110223335.png)
- 一旦目标文件 hello 中的代码和数据被加载到主存，处理器就开始执行 hello 程序的 main 程序中的机器语言指令。这些指令将 `"hello, world\n"` 字符串中的字节从主存复制到寄存器文件，再从寄存器文件中复制到显示设备，最终显示在屏幕上；
  ![](/images/CSAPP/Pasted%20image%2020250110223538.png)

### 5. 高速缓存至关重要

这个简单的示例揭示了一个重要的问题，即系统花费了大量的时间把信息从一个地方
挪到另一个地方。根据机械原理，较大的存储设备要比较小的存储设备运行得慢，而快速设备的造价远高于同类的低速设备。比如说，磁盘驱动器可能比主存大 1000 倍，但是对处理器而言，从磁盘驱动器上读取一个字的时间开销要比从主存中读取的开销大 1000 万倍 。类似地，寄存器文件只存储几百字节的信息，而主存里可存放几十亿字节。然而，处理器从寄存器文件中读数据比从主存中读取几乎要快 100 倍。随着这些年半导体技术的进步，处理器与主存之间的差距还在持续增大。**加快处理器的运行速度比加快主存的运行速度要容易和便宜得多**。

因此，系统设计者在CPU内部集成了更小更快的存储设备，称为**高速缓存存储器**（*cache memory*, 简称为 cache 或高速缓存）作为暂时的集结区域，存放处理器近期可能会需要的信息

![](/images/CSAPP/Pasted%20image%2020250110224140.png)

### 6. 存储设备形成层次结构

在处理器和一个较大较慢的设备（例如主存）之间插入一个更小更快的存储设备（例如
高速缓存）的想法很常见。在存储器层次结构中，从上至下，设备的访问速度越来越慢、容最越来越大，并且每字节的造价也越来越便宜。L1 高速缓存的容量可以达到数万字节，访问速度几乎和访问寄存器文件一样快；L2 高速缓存为数十万到数百万字节，访问时间比 L1 长 5 倍。现在的系统一般都会有至少三级高速缓存：L1、L2 和 L3。

![](/images/CSAPP/Pasted%20image%2020250111110219.png)

存储器层次结构的主要思想是**上一层的存储器作为低一层存储器的高速缓存**。因此，寄存器文件就是 L1 的高速缓存，L1 是 L2 的高速缓存，L2 是 L3 的高速缓存，L3 是主存的高速缓存，而主存又是磁盘的高速缓存。在某些具有分布式文件系统的网络系统中，本地磁盘就是存储在其他系统中磁盘上的数据的高速缓存。

### 7. 操作系统管理硬件

操作系统可以看成是应用程序和硬件之间插入的一层软件，如图所示。所有应用程序对硬件的操作尝试都必须通过操作系统。

![](/images/CSAPP/Pasted%20image%2020250111110702.png)

操作系统有两个基本功能：
1. 防止硬件被失控的应用程序滥用；
2. 向应用程序提供简单一致的机制来控制复杂而又通常大不相同的低级硬件设备。

操作系统通过几个基本的抽象概念（进程、虚拟内存和文件）来实现这两个功能，如下图所示。文件是对 I/O 设备的抽象表示，虚拟内存是对主存和磁盘 I/O 设备的抽象表示，进程则是对处理器、主存和 I/O 设备的抽象表示。

![](/images/CSAPP/Pasted%20image%2020250111110931.png)

#### 7.1. 进程

- **进程（process）**：操作系统对一个正在运行的程序的一种**抽象**。在一个系统上可以同时运行多个进程，而每个进程都好像在独占地使用硬件；
- **并发运行（concurrently）**：一个进程的指令和另一个进程的指令是交错执行的。在大多数系统中，需要运行的进程数是多于可以运行它们的 CPU 个数的。传统系统在一个时刻只能执行一个程序，而先进的多核处理器同时能够执行多个程序；
- **上下文（context）**：操作系统保持跟踪进程运行所需的所有状态信息，包括许多信息，比如 PC 和寄存器文件的当前值，以及主存的内容；
- **上下文切换（context switching）**：CPU 通过*进程间切换*并发地执行多个进程，当操作系统决定要把控制权从当前进程转移到某个新进程时，就会进行上下文切换，即保存当前进程的上下文、恢复新进程的上下文，然后将控制权传递到新进程。新进程就会从它上次停止的地方开始

下图展示了程序运行的基本理念。最开始，只有 shell 进程在运行，即等待命令行上的输入。当运行 hello 程序时，shell 通过调用系统调用来执行请求，系统调用会将控制权传递给操作系统。操作系统保存 shell 进程的上下文，创建一个新的 hello 进程及其上下文，然后将控制权传给新的 hello 进程。hello 进程终止后，操作系统恢复 shell 进程的上下文，并将控制权传回给它，shell 进程会继续等待下一个命令行输入。

![](/images/CSAPP/Pasted%20image%2020250111112208.png)

从一个进程到另一个进程的转换是由**操作系统内核** (*kernel*) 管理的。内核是操作系统代码常驻主存的部分。当应用程序需要操作系统的某些操作时，比如读写文件，它就执行一条特殊的*系统调用* (*system call*) 指令，将控制权传递给内核。然后内核执行被请求的操作并返回应用程序。**内核是系统管理全部进程所用代码和数据结构的集合**。

#### 7.2. 线程

一个进程实际上可以由多个称为**线程**的执行单元组成，每个线程都运行在进程的上下文中，并**共享同样的代码和全局数据**。多线程之间比多进程之间更容易共享数据。


#### 7.3. 虚拟内存

虚拟内存是一个**抽象概念**，它使得进程认为它拥有**连续的可用的内存**。而实际上，**它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换**。每个进程看到的内存都是一致的，称为**虚拟地址空间**。每个进程看到的虚拟地址空间由大量准确定义的区构成，每个区都有专门的功能。

![](/images/CSAPP/Pasted%20image%2020250111112757.png)

- **程序代码和数据（Program code and data）**：对所有的进程来说，代码是从同一固定地址开始，紧接着的是和 C 全局变量相对应的数据位置。代码和数据区是直接按照可执行目标文件的内容初始化的，在示例中就是可执行文件 hello。代码和数据区在进程一开始运行时就被指定了大小；
- **堆（Heap）**：调用像 malloc 和 free 这样的 C 标准库函数时，堆可以在运行时动态地扩展和收缩；
- **共享库（Shared libraries）**：用来存放像 C 标准库和数学库这样的共享库的代码和数据的区域；
- **栈（Stack）**：编译器用它来实现函数调用，和堆一样，栈在程序执行期间可以动态地扩展和收缩。每次我们调用一个函数时，栈就会增长；从一个函数返回时，栈就会收缩；
- **内核虚拟内存（Kernel virtual memory）**：为内核保留的。不允许应用程序读写这个区域的内容或者直接调用内核代码定义的函数。

#### 7.4. 文件

每个 I/O 设备，包括磁盘、键盘、显示器，甚至网络都可以看成是文件（Linux中的概念是**一切皆文件**）。系统中的所有输入输出都是通过使用一小组称为 **Unix I/O** 的系统函数调用读写文件来实现的。文件这个概念可以应用程序提供了一个统一的视图来看待不同的 I/O 设备，且程序员无需了解这些 I/O 设备的具体实现原理。

### 8. 系统之间利用网络通

当系统从主存复制一串字节到网络适配器时，数据流经过网络到达另一台机器。相似地，系统可以读取从其他机器发送来的数据，并把数据复制到自己的主存。电子邮件、微信QQ这
样的应用都是基于网络复制信息的功能。

![](/images/CSAPP/Pasted%20image%2020250111114127.png)

![](/images/CSAPP/Pasted%20image%2020250111114158.png)

### 9. 重要主题

#### 9.1. Amdahl 定律

该定律的主要思想是，当对系统的某个部分加速时，其对系统整体性能的影响取决于**该部分的重要性和加速程度**。

**Amdahl 定律** (*Amdahl's law*) 如下：

$$
\begin{align*} 
T_{new} &= (1 - \alpha)T_{old}+(\alpha T_{old})/k \\
&=T_{old}[(1 - \alpha)+\alpha/k]\\
\end{align*}
$$

**加速比**：

$$S=\frac 1{(1-\alpha)+\alpha/k}$$
- $T_{old}$：系统执行某应用程序需要时间
- $\alpha$：系统执行某应用程序需要时间与该时间的比例
- $k$：该部分性能提升比例

举个例子，系统的某个部分初始耗时比例为 60%($\alpha$=0.6), 其加速比例因子为 3($k$=3) ，则加速比为 $1/[0. 4+0. 6/3]=1.67$ 倍。虽然对系统的一个主要部分做出了重大改进，但是获得的系统加速比却明显小于这部分的加速比。这就是Amdahl 定律的主要观点——**要想显著加速整个系统，必须提升全系统中相当大的部分的速度**。

当 $k$ 趋向于无穷时，即系统这部分花费的时间可以忽略不计，可以得到：

$$S=\frac 1{(1-\alpha)}$$

举个例子，如果 60% 的系统能够加速到不花时间的程度，获得的净加速比将仍只有
$1/ 0.4=2.5$ 倍。

#### 9.2. 井发和并行

- **并发（concurrency）**：指一个系统**能够同时处理多个任务**。在单处理器系统中，多个任务交替执行，通过上下文切换使得在宏观上看起来像是多个任务同时进行[1](https://blog.csdn.net/scarificed/article/details/114645082)。例如一个人同时吃三个馒头，这就是并发；
- **并行 (parallelism)** ：系统同时执行多个任务，每个任务在不同的处理器核心上执行[2](https://blog.csdn.net/Long_xu/article/details/135730509)。例如三个人同时吃三个馒头，这就是并行；


##### 9.2.1. 线程级并发

并发强调的是在单位时间内有多个任务同时进行，但这些任务可能是交替执行的。而并行强调的是在同一时刻有多个任务同时进行[3](https://blog.csdn.net/qq_34173920/article/details/106191047)。并发可以在单处理器系统中实现，而并行则需要多处理器或多核处理器系统。

![](/images/CSAPP/Pasted%20image%2020250111120704.png)

下图是多核处理器的组织结构，其中 L1 高速缓存分为两个部分——一个保存最近取到的指令，另一个存放数据。这些核共享更高层次的高速缓存，以及到主存的接口。

![](/images/CSAPP/Pasted%20image%2020250111120908.png)

超线程，也称为**同时多线程** (*simultaneous multi-threading*)，允许一个 CPU 执行多个控制流的技术。它的工作原理是将一颗物理 CPU 虚拟化为两颗逻辑 CPU，即 CPU 某些硬件有多个备份，比如程序计数器和寄存器文件而其他的硬件部分只有一份，比如执行浮点算术运算的单元。在超线程技术的支持下，CPU 可以**在单个时钟周期的基础上决定要执行哪一个线程**。这使得CPU能够更好地利用它的处理资源，避免了常规 CPU 在不同线程间切换所需的大量时钟周期，提高了计算效率。

##### 9.2.2 指令级井行

指在一个处理器内部，利用**流水线**(*pipelining*)、超标量、乱序执行等技术，使得多条指令可以同时或部分重叠地执行，从而提高指令的执行速度。

- **流水线（pipeline）**：将每条指令分解为多个步骤，并让各个步骤重叠执行，从而实现多条指令并行处理的技术；
- **超标量（superscalar）**：在CPU中有多条流水线，并且每个时钟周期内可以完成多条指令的技术

##### 9.2.3. 单指令、多数据并行

即 **SIMD 并行**（*Single-Instruction, Multiple-Data*），是一种**指令级并行**架构，允许**在同一时钟周期内对多个数据元素执行相同的指令**。通过同时处理多个数据，SIMD能够显著提高计算性能，尤其是在处理大规模数据和执行重复性计算任务时。例如，较新几代的 Intel 和 AMD 处理器都具有并行地对 8 对单精度浮点数 (C 数据类型 float) 做加法的指令。SIMD 指令多是为了提高处理影像、声音和视频数据应用的执行速度。

#### 9.3. 计算机系统中抽象的重要性

抽象的使用是计算机科学中最为重要的概念之一。例如，为一组函数规定一个简单的应用程序接口 (API) 就是一个很好的编程习惯，程序员无须了解它内部的工作便可以使用这些代码。不同的编程语言提供不同形式和等级的抽象支持，例如 Java 类的声明和 C 语言的函数原型。

下图是基于前文的堆计算机系统进一步的抽象概念。在处理器里，**指令集架构**提供了对实际处理器硬件的抽象。使用这个抽象概念，机器代码程序就好像运行在一个一次只执行一条指令的处理器上。而虚拟机提供对整个计算机的抽象，其思想是 IBM 在 20 世纪 60 年代提出来的，常用的虚拟机软件有 VMware，在双系统开发平台上非常常用。

![](/images/CSAPP/Pasted%20image%2020250111122739.png)

### 10. 小结

计算机系统是由硬件和系统软件组成的，它们共同协作以运行应用程序。计算机内部的信息被表示为一组组的位，它们依据上下文有不同的解释方式。程序被其他程序翻译成不同的形式，开始时是 ASCII 文本，然后被编译器和链接器翻译成二进制可执行文件。

处理器读取并解释存放在主存里的二进制指令。因为计算机花费了大量的时间在内存、
I/O 设备和 CPU 寄存器之间复制数据，所以将系统中的存储设备划分成层次结构——CPU 寄存器在顶部，接着是多层的硬件高速缓存存储器、DRAM 主存和磁盘存储器。在层次模型中，位于更高层的存储设备比低层的存储设备要更快，单位比特造价也更高。层次结构中较高层次的存储设备可以作为较低层次设备的高速缓存。通过理解和运用这种存储层次结构的知识，程序员可以优化 C 程序的性能。

操作系统内核是应用程序和硬件之间的媒介。它提供三个基本的抽象：
1. 文件是对 I/O 设备的抽象；
2. 虚拟内存是对主存和磁盘的抽象；
3. 进程是处理器、主存和 I/O 设备的抽象。

最后，网络提供了计算机系统之间通信的手段。从特殊系统的角度来看，网络就是一种 I/O 设备。

---

## 参考引用

### 书籍出处

- [深入理解计算机系统 (Randal E. Bryant, David R. O’Hallaron)](asset/Computer%20Network/深入理解计算机系统%20(Randal%20E.%20Bryant,%20David%20R.%20O’Hallaron).pdf)
- [Computer.Systems.A.Programmers.Perspective.3rd.Global.Edition.2015.7](asset/Computer%20Network/Computer.Systems.A.Programmers.Perspective.3rd.Global.Edition.2015.7.pdf)

### 网页链接

- [虚拟内存是什么？它有什么用？又该如何设置呢？_虚拟内存,解决哪些场景问题-CSDN博客](https://blog.csdn.net/sunyctf/article/details/128886418)
- [并发与并行的区别（超级通俗易懂）_并发和并行区别秒懂-CSDN博客](https://blog.csdn.net/scarificed/article/details/114645082)
- [一文搞懂程序、进程、线程、并发、并行、高并发的概念-CSDN博客](https://blog.csdn.net/Long_xu/article/details/135730509)
- [并发(Concurrent)和并行(parallel)的区别_parallel concurrent-CSDN博客](https://blog.csdn.net/qq_34173920/article/details/106191047)
- [深入了解超线程技术：虚拟化CPU线程的革命性技术](https://cloud.baidu.com/article/2944145)
- [指令级并行ISA（Instruction Set Architecture）—— SIMD（单指令多数据）模型详解-CSDN博客](https://blog.csdn.net/qq_44648285/article/details/143496131)