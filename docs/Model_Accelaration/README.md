
## 模型加速方法概述

- [网络模型设计]
- [模型剪枝简介]()
- [模型量化简介](/docs/Model_Accelaration/模型量化简介.md)
- [网络搜索]

## 方法实现

### 轻量化网络

### 知识蒸馏

### 模型剪枝

### 模型量化

#### 量化感知训练

#### 后训练量化

- [TFLite]()
- [AdaRound](/docs/Model_Accelaration/PTQ/AdaRound.md) 

#### 无校准集

- [A Survey of Quantization Methods for Efficient Neural Network Inference](https://arxiv.org/abs/2103.13630) 里面有介绍

#### 低比特量化

##### 二值量化

A Review of Binarized Neural Networks


https://arxiv.org/abs/2110.06804

https://arxiv.org/abs/1605.04711

https://arxiv.org/abs/1602.02830

https://arxiv.org/abs/1603.05279

IR-Net: Forward and Backward Information Retention for Highly Accurate Binary Neural Networks

DMS: Differentiable diMension Search for Binary Neural Networks

##### INT8 量化

Towards Unified INT8 Training for Convolutional Neural Network

8-bit-inference-with-tensorrt CSDN 知乎

https://arleyzhang.github.io/articles/923e2c40/

https://note.youdao.com/ynoteshare/index.html?id=829ba6cabfde990e2832b048a4f492b3&type=note&_time=1711435479349#/

https://zhuanlan.zhihu.com/p/405571578

https://arxiv.org/abs/2004.09602

https://zhuanlan.zhihu.com/p/509353790

https://zhuanlan.zhihu.com/p/38328685?utm_campaign=shareopn&utm_medium=social&utm_oi=944480243856162816&utm_psn=1573017689664139264&utm_source=wechat_session

##### 任意bit量化

##### FP8量化

https://zhuanlan.zhihu.com/p/565021881

https://www.qinglite.cn/doc/164964781e4aa7db6


## 深度学习算法优化


- [BN折叠](/docs/Model_Accelaration/模型量化简介.md#批归一化折叠-batch-normalization-folding)




## 参考引用

### 论文地址



### 博客


（这个在文档已添加链接）
- [深度学习算法优化系列十一 | 折叠Batch Normalization](https://zhuanlan.zhihu.com/p/107913057)