# 具身智能简介 A Survey of Embodied AI

## 摘要 Abstract

从“互联网 AI”时代到“具身智能”时代出现了一种新兴的范式转变，其中AI算法和智能体（agent）不再主要通过从互联网的图像、视频或文本数据集中学习。相反，它们通过与环境的互动，从类似人类的自我中心感知（egocentric perception）中学习。因此，对支持各种 **具身智能（embodied AI）** 研究任务的具身AI模拟器（simulators）的需求大幅增长。人们对具身智能的兴趣与日俱增，这有利于人们对通用人工智能（AGI）的更大追求。

## 介绍 INTRODUCTION

近年来，深度学习、强化学习、计算机图形学和机器人学领域取得的进展，使人们对开发通用人工智能系统的兴趣与日俱增。因此，人工智能领域已经从侧重于从互联网上的图像、视频和文本数据集学习的“互联网人工智能”转向了“具身智能”，使智能体能够通过与周围环境的互动来学习。具身智能认为，真正的智能可以从智能体（Agent）与环境的交互（interaction）中产生。但就目前而言，具身智能是将视觉、语言和推理等传统智能概念融入人工实体中，以帮助解决虚拟环境中的人工智能问题。

本文涵盖了过去四年中开发的以下九种具身人工智能模拟器：

- DeepMind Lab [12]
- AI2-THOR [13]
- CHALET [14]
- VirtualHome [15]
- VRKitchen [16]
- Habitat-Sim [17]
- iGibson [18]
- SAPIEN [19]
- ThreeDWorld [20]

这些具身智能模拟器在计算机模拟中提供了现实世界的真实再现，主要采用房间或公寓的配置，为环境提供某种形式的约束。这些模拟器大多由物理引擎、Python API 和可在环境中控制或操纵的人工智能体组成。

具身人工智能模拟器催生了一系列潜在的具身人工智能研究任务，例如 **视觉探索(visual exploration)**、**视觉导航(visual navigation)** 和 **具身问答(embodied QA)**。本文将重点关注这三个任务，这三个任务在复杂度上也有联系。

- **视觉探索**：是视觉导航中非常有用的组成部分，用于真实情境
- **视觉导航**：
- **具身问答**：进一步涉及复杂的问答能力，建立在视觉和语言导航的基础上。由于语言是一种常见的模态，而视觉问答在人工智能中是一项流行的任务，因此具身问答是具身人工智能的自然方向。

## 具身智能模拟器 SIMULATORS FOR EMBODIED AI

![具身智能模拟器比较](/images/Embodied_AI/Tables%20for%20Embodied%20AI.png)

本节将根据七个技术特征全面比较这九个具身人工智能模拟器，因为它们涵盖了准确复制环境、与物理世界的交互和状态所需的基本方面，因此为测试具有具身智能的合适测试平台提供了基础，如Table 1。这七个特征是：**环境、物理、物体类型、物体属性、控制器、行动和多智能体**。

**环境（Environment）**：构建具身智能模拟器环境的两种主要方法是 **基于游戏场景构建（G）** 和 **基于世界场景构建（W）**。如图1，基于游戏的场景是由3D资产构建的，而基于世界的场景是由对象和环境的真实世界扫描构建的。

- 完全由3D资产构建的3D环境通常具有内置的物理特性和物体类别，在与由真实世界扫描构建的环境的3D网格相比时，这些类别被很好地分割出来。清晰的对象分割使得很容易将它们建模为具有可移动关节的关节对象，例如在 PartNet 中提供的3D模型。
- 相比之下，环境和物体的真实世界扫描提供了更高的保真度和更准确的真实世界表示，有助于更好地将智能体性能从模拟转移到真实世界。正如Table 1中所观察到的，除了 Habitat-Sim 和 iGibson 外，大多数模拟器都具有基于游戏的场景，因为基于世界的场景构建需要更多的资源。

![具身智能构建环境](/images/Embodied_AI/Comparison%20between%20game-based%20scene%20and%20world-based%20scene.png)

**物理学（Physics）**：模拟器不仅必须构建逼真的环境，还还需要模拟真实世界物理特性的智能体与物体或物体与物体之间的逼真交互。通过研究模拟器的物理特性，广义上可将其分为**基本物理特性（B）** 和 **高级物理特性（A）**。如图2，基本物理特性包括**碰撞（collision），刚体动力学（rigid-body dynamics）和重力建模（gravity modelling）**，而高级物理特性包括**布料（cloth）、流体（fluid）和软体物理（soft-body physics）**。由于大多数具身智能模拟器构建基于游戏的场景，具有内置的物理引擎，配备了基本的物理特性。另一方面，对于像ThreeDWorld这样的模拟器，其目标是了解复杂物理环境如何塑造人工智能体在环境中的决策，它们配备了更先进的物理能力。对于专注于交互式导航任务的模拟器来说，基本的物理特性通常已经足够。

![具身智能物理学模拟](/images/Embodied_AI/Physics%20for%20Embodied%20AI.png)

**物体类型（Object Type）**：如图3所示，用于创建模拟器的物体主要有两种来源。
- 第一种类型是**数据集驱动环境**，其中的物体主要来自现有的物体数据集，例如SUNCG数据集、Matterport3D数据集和Gibson数据集。
- 第二种类型是**资产驱动环境**，其中的对象来自网络，例如Unity 3D游戏商店。

两种来源之间的一个区别是**物体数据集的可持续性**。数据集驱动型物体的收集成本高于资产驱动型物体，因为任何人都可以在线贡献3D物体模型。然而，与数据集驱动型物体相比，资产驱动型物体更难确保三维物体模型的质量。基于游戏的具身智能模拟器更有可能从资产商店获取其对象数据集，而基于世界的模拟器则倾向于从现有的3D对象数据集导入其对象数据集。

![具身智能物体类型](/images/Embodied_AI/Object%20Type%20for%20Embodied%20AI.png)

**物体属性（Object Property）**：一些模拟器仅允许具有基本交互性（如碰撞）的对象。高级模拟器允许具有更精细的交互性，例如多状态变化。例如，当苹果被切割时，它会经历一个状态变化，变成苹果片。因此，可将这些不同级别的物体交互分类为 **具有可交互对象（I）和多状态对象（M）** 的模拟器。如 Table 1，一些模拟器，如AI2-THOR 和 VRKitchen，允许多个状态变化，为了解对象在受到作用时如何反应和改变其状态提供了一个平台。

**控制器（Controller）**：参考图4，用户与模拟器之间的控制器接口有不同类型，从直接的Python API控制器（P）和虚拟机器人控制器（R）到虚拟现实控制器（V）。具身机器人允许对现有的真实世界机器人进行虚拟交互，例如通用机器人5（UR5）和TurtleBot V2，并可以直接使用ROS接口进行控制。虚拟现实控制器界面提供更具沉浸感的人机交互，并促进了使用其真实世界对应物的部署。例如，主要设计用于视觉导航的模拟器，如iGibson 和 AI2-THOR，也配备有虚拟机器人控制器，以便在其真实世界对应物中轻松部署，例如iGibson的Castro和RoboTHOR分别。

![具身智能控制器](/images/Embodied_AI/Embodied%20AI%20controller.png)

**行动（Action）**：在具身智能模拟器中，人工智能智能体的行动能力存在复杂程度的差异，从仅能执行基本的导航操作到通过虚拟现实界面进行更高级别的人机交互操作。本文将它们分类为三个层次的机器人操纵：**导航（N）、原子动作（A）和人机交互（H）**。

- 导航最低层，是所有具身人工智能模拟器中的常见功能。它由智能体的能力来在其虚拟环境中导航来定义。
- 原子动作为智能体提供了一种执行对感兴趣的对象进行基本离散操作的方式，并且在大多数具身智能模拟器中都存在。
- 人机交互是虚拟现实控制器的结果，因为它使人类能够实时控制虚拟智能体与模拟世界实时学习和互动。
  
大多数基于导航的大型模拟器，例如AI2-THOR、iGibson 和 Habitat-Sim，往往具有导航、原子动作和ROS，这使它们能够在执行诸如点导航或对象导航等任务时提供更好的控制和物体操纵。另一方面，像ThreeDWorld 和 VRKitchen 这样的模拟器属于人机交互类别，因为它们的构造是为了提供高度逼真的物理模拟和多种状态变化。这只有通过人机交互才能实现，因为在与这些虚拟物体进行交互时，需要人类级别的灵巧性（dexterity）。

**多智能体（Multi-agent）**：参考 Table 1，只有少数模拟器，如AI2-THOR、iGibson 和 ThreeDWorld，配备了多智能体设置，因为当前涉及多智能体强化学习的研究相对较少。一般来说，模拟器需要丰富的对象内容，才能构建出用于对抗和协作训练的多智能体特征。由于缺乏多智能体支持的模拟器，这些具身智能模拟器中的多智能体特性的研究任务较少。

对于基于多智能体强化学习的训练，目前仍在OpenAI Gym环境中进行。存在两种不同的多智能体设置。
- 第一种是 avatar-based （AT）的多智能体，例如在ThreeDWorld中，它允许人工智能体与模拟头像进行交互。
- 第二种是基于用户（U）的多智能体，例如在AI2-THOR中，它们可以扮演双重学习网络的角色，并与模拟中的其他人工智能体进行交互，以完成共同的任务。


## 参考引用

### 论文地址

- [A Survey of Embodied AI: From Simulators to Research Tasks](https://arxiv.org/abs/2103.04918)

### 博客地址

- [【具身智能综述1】 A Survey of Embodied AI: From Simulators to Research Tasks](http://www.chinasem.cn/article/255208)