# 具身智能简介 A Survey of Embodied AI

## 摘要 Abstract

从“互联网 AI”时代到“具身智能”时代出现了一种新兴的范式转变，其中AI算法和智能体（agent）不再主要通过从互联网的图像、视频或文本数据集中学习。相反，它们通过与环境的互动，从类似人类的自我中心感知（egocentric perception）中学习。因此，对支持各种 **具身智能（embodied AI）** 研究任务的具身AI模拟器（simulators）的需求大幅增长。人们对具身智能的兴趣与日俱增，这有利于人们对通用人工智能（AGI）的更大追求。

## 介绍 INTRODUCTION

近年来，深度学习、强化学习、计算机图形学和机器人学领域取得的进展，使人们对开发通用人工智能系统的兴趣与日俱增。因此，人工智能领域已经从侧重于从互联网上的图像、视频和文本数据集学习的“互联网人工智能”转向了“具身智能”，使智能体能够通过与周围环境的互动来学习。具身智能认为，真正的智能可以从智能体（Agent）与环境的交互（interaction）中产生。但就目前而言，具身智能是将视觉、语言和推理等传统智能概念融入人工实体中，以帮助解决虚拟环境中的人工智能问题。

本文涵盖了过去四年中开发的以下九种具身人工智能模拟器：

- DeepMind Lab [12]
- AI2-THOR [13]
- CHALET [14]
- VirtualHome [15]
- VRKitchen [16]
- Habitat-Sim [17]
- iGibson [18]
- SAPIEN [19]
- ThreeDWorld [20]

这些具身智能模拟器在计算机模拟中提供了现实世界的真实再现，主要采用房间或公寓的配置，为环境提供某种形式的约束。这些模拟器大多由物理引擎、Python API 和可在环境中控制或操纵的人工智能体组成。

具身人工智能模拟器催生了一系列潜在的具身人工智能研究任务，例如 **视觉探索(visual exploration)**、**视觉导航(visual navigation)** 和 **具身问答(embodied QA)**。本文将重点关注这三个任务，这三个任务在复杂度上也有联系。

- **视觉探索**：是视觉导航中非常有用的组成部分，用于真实情境
- **视觉导航**：
- **具身问答**：进一步涉及复杂的问答能力，建立在视觉和语言导航的基础上。由于语言是一种常见的模态，而视觉问答在人工智能中是一项流行的任务，因此具身问答是具身人工智能的自然方向。

## 具身智能模拟器 SIMULATORS FOR EMBODIED AI

### 具身智能模拟器特征 Embodied AI Simulators

![具身智能模拟器比较](/images/Embodied_AI/Tables%20for%20Embodied%20AI.png)

本节将根据七个技术特征全面比较这九个具身人工智能模拟器，因为它们涵盖了准确复制环境、与物理世界的交互和状态所需的基本方面，因此为测试具有具身智能的合适测试平台提供了基础，如Table 1。这七个特征是：**环境、物理、物体类型、物体属性、控制器、行动和多智能体**。

**环境（Environment）**：构建具身智能模拟器环境的两种主要方法是 **基于游戏场景构建（G）** 和 **基于世界场景构建（W）**。如图1，基于游戏的场景是由3D资产构建的，而基于世界的场景是由对象和环境的真实世界扫描构建的。

- 完全由3D资产构建的3D环境通常具有内置的物理特性和物体类别，在与由真实世界扫描构建的环境的3D网格相比时，这些类别被很好地分割出来。清晰的对象分割使得很容易将它们建模为具有可移动关节的关节对象，例如在 PartNet 中提供的3D模型。
- 相比之下，环境和物体的真实世界扫描提供了更高的保真度和更准确的真实世界表示，有助于更好地将智能体性能从模拟转移到真实世界。正如Table 1中所观察到的，除了 Habitat-Sim 和 iGibson 外，大多数模拟器都具有基于游戏的场景，因为基于世界的场景构建需要更多的资源。

![具身智能构建环境](/images/Embodied_AI/Comparison%20between%20game-based%20scene%20and%20world-based%20scene.png)

**物理学（Physics）**：模拟器不仅必须构建逼真的环境，还还需要模拟真实世界物理特性的智能体与物体或物体与物体之间的逼真交互。通过研究模拟器的物理特性，广义上可将其分为**基本物理特性（B）** 和 **高级物理特性（A）**。如图2，基本物理特性包括**碰撞（collision），刚体动力学（rigid-body dynamics）和重力建模（gravity modelling）**，而高级物理特性包括**布料（cloth）、流体（fluid）和软体物理（soft-body physics）**。由于大多数具身智能模拟器构建基于游戏的场景，具有内置的物理引擎，配备了基本的物理特性。另一方面，对于像ThreeDWorld这样的模拟器，其目标是了解复杂物理环境如何塑造人工智能体在环境中的决策，它们配备了更先进的物理能力。对于专注于交互式导航任务的模拟器来说，基本的物理特性通常已经足够。

![具身智能物理学模拟](/images/Embodied_AI/Physics%20for%20Embodied%20AI.png)

**物体类型（Object Type）**：如图3所示，用于创建模拟器的物体主要有两种来源。
- 第一种类型是**数据集驱动环境**，其中的物体主要来自现有的物体数据集，例如SUNCG数据集、Matterport3D数据集和Gibson数据集。
- 第二种类型是**资产驱动环境**，其中的对象来自网络，例如Unity 3D游戏商店。

两种来源之间的一个区别是**物体数据集的可持续性**。数据集驱动型物体的收集成本高于资产驱动型物体，因为任何人都可以在线贡献3D物体模型。然而，与数据集驱动型物体相比，资产驱动型物体更难确保三维物体模型的质量。基于游戏的具身智能模拟器更有可能从资产商店获取其对象数据集，而基于世界的模拟器则倾向于从现有的3D对象数据集导入其对象数据集。

![具身智能物体类型](/images/Embodied_AI/Object%20Type%20for%20Embodied%20AI.png)

**物体属性（Object Property）**：一些模拟器仅允许具有基本交互性（如碰撞）的对象。高级模拟器允许具有更精细的交互性，例如多状态变化。例如，当苹果被切割时，它会经历一个状态变化，变成苹果片。因此，可将这些不同级别的物体交互分类为 **具有可交互对象（I）和多状态对象（M）** 的模拟器。如 Table 1，一些模拟器，如AI2-THOR 和 VRKitchen，允许多个状态变化，为了解对象在受到作用时如何反应和改变其状态提供了一个平台。

**控制器（Controller）**：参考图4，用户与模拟器之间的控制器接口有不同类型，从直接的Python API控制器（P）和虚拟机器人控制器（R）到虚拟现实控制器（V）。具身机器人允许对现有的真实世界机器人进行虚拟交互，例如通用机器人5（UR5）和TurtleBot V2，并可以直接使用ROS接口进行控制。虚拟现实控制器界面提供更具沉浸感的人机交互，并促进了使用其真实世界对应物的部署。例如，主要设计用于视觉导航的模拟器，如iGibson 和 AI2-THOR，也配备有虚拟机器人控制器，以便在其真实世界对应物中轻松部署，例如iGibson的Castro和RoboTHOR分别。

![具身智能控制器](/images/Embodied_AI/Embodied%20AI%20controller.png)

**行动（Action）**：在具身智能模拟器中，人工智能智能体的行动能力存在复杂程度的差异，从仅能执行基本的导航操作到通过虚拟现实界面进行更高级别的人机交互操作。本文将它们分类为三个层次的机器人操纵：**导航（N）、原子动作（A）和人机交互（H）**。

- 导航最低层，是所有具身人工智能模拟器中的常见功能。它由智能体的能力来在其虚拟环境中导航来定义。
- 原子动作为智能体提供了一种执行对感兴趣的对象进行基本离散操作的方式，并且在大多数具身智能模拟器中都存在。
- 人机交互是虚拟现实控制器的结果，因为它使人类能够实时控制虚拟智能体与模拟世界实时学习和互动。
  
大多数基于导航的大型模拟器，例如AI2-THOR、iGibson 和 Habitat-Sim，往往具有导航、原子动作和ROS，这使它们能够在执行诸如点导航或对象导航等任务时提供更好的控制和物体操纵。另一方面，像ThreeDWorld 和 VRKitchen 这样的模拟器属于人机交互类别，因为它们的构造是为了提供高度逼真的物理模拟和多种状态变化。这只有通过人机交互才能实现，因为在与这些虚拟物体进行交互时，需要人类级别的灵巧性（dexterity）。

**多智能体（Multi-agent）**：参考 Table 1，只有少数模拟器，如AI2-THOR、iGibson 和 ThreeDWorld，配备了多智能体设置，因为当前涉及多智能体强化学习的研究相对较少。一般来说，模拟器需要丰富的对象内容，才能构建出用于对抗和协作训练的多智能体特征。由于缺乏多智能体支持的模拟器，这些具身智能模拟器中的多智能体特性的研究任务较少。

对于基于多智能体强化学习的训练，目前仍在OpenAI Gym环境中进行。存在两种不同的多智能体设置。
- 第一种是 avatar-based （AT）的多智能体，例如在ThreeDWorld中，它允许人工智能体与模拟头像进行交互。
- 第二种是基于用户（U）的多智能体，例如在AI2-THOR中，它们可以扮演双重学习网络的角色，并与模拟中的其他人工智能体进行交互，以完成共同的任务。

### 模拟器比较 Comparison of Embodied AI Simulators

根据这七个特征艾伦人工智能研究所关于具身人工智能的研究，我们提出了模拟器的第二套评估特征。如Table 1 所示，它包括三个关键特征：**逼真度（realism）**，**可扩展性（scalability）** 和 **交互性（interactivity）**。

- 3D 环境的逼真性可以归因于模拟器的环境和物理。环境模拟了现实世界的物理外观，而物理模拟了现实世界内的复杂物理属性。
- 3D 环境的可扩展性可以归因于对象类型。通对于数据集驱动的物体，可通过收集更多现实世界的三维扫描数据来扩展；对于资产驱动的物体，可通过购买更多三维资产来扩展。
- 交互性归因于物体属性、控制器、行动和多智能体。
  
根据具身智能模拟器的次要评估特征，表 I 和图 6 中的七个主要特征，具有上述三个次要特征的模拟器（例如 AI2-THOR、iGibson 和 Habitat-Sim）更受欢迎，广泛用于各种具身智能研究任务。此外，还对所有具身智能模拟器进行了全面的定量比较，以比较每个模拟器的环境配置和技术性能。环境配置特征在很大程度上取决于模拟器创建者建议的应用程序，而其他特征，如技术规格和渲染性能，则主要取决于用于创建的模拟引擎。与其他模拟器相比，AI2-THOR 具有最大的环境配置，而 Habitat-Sim 和 iGibson 在图形渲染性能方面是排名前两位的表现者。表 II 中显示的定量性能基准进一步展示了这三个具身人工智能模拟器的优越性和复杂性。这些具身智能模拟器的比较进一步强调了本文建立的七个主要评估指标和三个次要评估的重要性，以帮助选择研究任务的理想模拟器。

![Connections between Embodied AI simulators to research](/images/Embodied_AI/Connections%20between%20Embodied%20AI%20simulators%20to%20research.png)

## 具身智能研究 RESEARCH IN EMBODIED AI

近来具身人工智能研究的增长有多种动因。从认知科学和心理学角度来看，具身假说认为，智能产生于与环境的互动，是感觉运动活动的结果。直观地说，人类不仅仅通过互联网人工智能范式学习，在这种范式中，大多数经验是随机的和被动的（即外部策划的）。人类还通过主动感知、运动、互动和交流来学习。从人工智能的角度来看，与传统方法相比，目前的具身智能研究任务由于涉及到学习，因此可以使机器人能力（如绘图和导航）在未知环境中具有更强的泛化能力，对传感器噪声也具有更强的鲁棒性。具身智能还能够通过基于学习的方法轻松整合各种形式的信息，如深度、语言和音频，从因此具身人工智能还具有灵活性，并可能带来更高的性能。

具身智能研究任务的三种主要类型是**视觉探索、视觉导航和具身问答**。大多数具身智能的现有论文要么专注于这些任务，要么利用为这些任务引入的模块来构建更复杂的任务模型，如音频-视觉导航。随着任务从探索到问答的发展，其复杂性也在增加。每个任务都构成了下一个任务的基础，形成了图 5 中所示的具身人工智能研究任务的金字塔结构。

![embodied AI research tasks](/images/Embodied_AI/embodied%20AI%20research%20tasks.png)

![SUMMARY OF EMBODIED AI RESEARCH TASKS](/images/Embodied_AI/SUMMARY%20OF%20EMBODIED%20AI%20RESEARCH%20TASKS.png)

### 视觉探索 Visual Exploration

在视觉探索中，智能体通过运动和感知收集关于3D环境信息，用于更新内部环境模型以提高效率（例如，尽可能减少步骤）。内部模型可以是拓扑图（topological graph map）、语义图（semantic map）、占位图（occupancy map）或空间记忆（spatial memory）等形式。这些基于图的架构（map-based architectures）可以捕捉几何图形和语义，与反应式（reactive）和递归神经网络策略相比，可以实现更高效的策略学习和规划。视觉探索通常在导航任务之前或同时进行。

- 在第一种情况下，视觉探索会建立内部记忆，作为下游导航任务中路径规划的先验。在导航开始前，智能体可在一定预算（如有限的步数）内自由探索环境。
- 在后一种情况下，智能体在导航未见过的测试环境时构建地图，这使得它与下游任务结合得更加紧密。

在传统的机器人技术中，探索是通过被动或主动的同步定位和绘图（simultaneous localisation and mapping，SLAM）来完成的，以建立环境地图。然后将该地图与定位和路径规划一起用于导航任务。SLAM 的研究非常深入，但纯粹的几何方法仍有改进的余地。由于它们依赖于传感器，因此容易受到测量噪声的影响，需要进行大量的微调。另一方面，基于学习的方法通常使用 RGB 或深度传感器，对噪声具有更强的鲁棒性。此外，视觉探索中基于学习的方法允许人工智能结合语义理解（如环境中的物体类型），并以无监督的方式归纳其先前所见环境的知识，以帮助理解新环境。这就减少了对人类的依赖，从而提高了效率。

学会以地图的形式创建有用的内部环境模型，可以提高机器人的性能，无论是在完成任务之前（即未指定的下游任务）还是与下游任务同时进行，都是如此。智能探索对于需要探索随时间动态发展的新环境的智能体也特别有用，例如救援机器人和深海探索机器人。






## 参考引用

### 论文地址

- [A Survey of Embodied AI: From Simulators to Research Tasks](https://arxiv.org/abs/2103.04918)

### 博客地址

- [【具身智能综述1】 A Survey of Embodied AI: From Simulators to Research Tasks](http://www.chinasem.cn/article/255208)